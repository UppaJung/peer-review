# Rejecting the use of *Reject* in Scientific Peer Review

Scientific peer review should *advance* science. It should promote and protect the integrity of scientific research by identifying missteps, errors, and other causes for concern that might otherwise go undetected or undisclosed. It should empower authors with others' expertise and insights to make us better scientists and communicators.

But the rituals we call “peer review” often *hinder* science, not advance it.

We often practice peer review to select research works for inclusion in exclusive publications, or other forms of recognition, under the pretense of protecting scientific integrity. We select for works of ‘*significance*’, not just scientific integrity, and ‘*significance*’ cannot help but compete with integrity and [undermine it](./The-Harms-of-Exclusionary-Peer-Reivew.md). We segregate works into *accepts* and *rejects* without evidence we can do so reliably; in the few well-designed experiments of peer review, [half of the works accepted by one review were rejected by a parallel review](./Notes.md#replicability). 

The problem is not merely that ‘*significance*’ is subjective. We could not objectively categorize works into *accepts* and *rejects* even if scientific integrity were our only review criteria. There are many dimensions to scientific integrity, and compressing them into a boolean is lossy and perilous. Nor is it necessary.

The power to *reject* work may seem necessary, as there is no more powerful tool to prevent deeply-flawed work from misleading its audience than to prevent that work from reaching the audience. from being published seems the surest way to prevent it from misleading others. However, a *reject* cannot prevent authors from distributing results, possibly with the endorsement of a subsequent, less-diligent, review process.

Further, the power to *reject* has consequences beyond a single work that we might want to censor. Our decision to *accept* works we had the power to *reject* will inevitably be construed as endorsements, though accepted works are rarely without limitations and shortcomings that many readers will overlook. Our choices will inevitably mislead anyone who does not perfectly understand where we draw the line between *accept* and *reject*. Another consequence of our power to *reject* work, and prevents its publication, is that rejections conceal authors' missteps from those who might study or learn from them, making it harder for science to learn from our collective mistakes.

Further, holding power over whether a work will published reduces our objectivity as reviewers. The moment we start leaning toward an accept or reject outcome, [confirmation bias](https://en.wikipedia.org/wiki/Confirmation_bias) may lead us to favor observations that support that outcome. We may be unfairly ignore observations that support the alternative, as they create dissonance with our belief that we chose the fair objective outcome.

The product of *scientific* peer review should not be a decision to *accept* or *reject* a work, but a collection of insights to be shared with the work's authors *and* audience. This *scientific* peer review should be strictly isolated from peer review that segregates works worthy of publication, or other recognition, from works to *reject*. 




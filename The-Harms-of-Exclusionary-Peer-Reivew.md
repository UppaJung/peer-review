## The Harms of *Exclusionary* Peer Review

There are many ways *exclusionary* peer review harms scientific writing and causes science to mislead ourselves and others. (For more background, see the adjoining [recommended readings](./Recommended-Readings.md).)

<a id="delaying-spread-of-knowledge"></a>
#### It delays the spread of knowledge
Because comparing competing submissions takes time, authors must often wait to submit their research until a common deadline, reviewers need time to read a cohort of submissions to compare them against each other, and committees need time to collectively discuss which papers to accept. These delays can add months to each submission cycle. Research that needs to be submitted three times to find a publication that considers it on brand may take over a year to be accepted and longer to publish. In many fields, the value of research can decline significantly while it awaits a single round of exclusionary peer review (with extreme examples being research on the detection and prevention of emerging diseases or of research identifying election misinformation campaigns).

<a id="delays-disrupt-memory"></a>
#### Its delays disrupt authors' work and degrade our memories.
Time decays our ability to recall how we conducted our experiments, our observations during the experiments, and the tooling we used to process data and document our results. By the time have access to reviewers' feedback identifying what we failed to document, we may have already forgotten details that reviewers noticed we had elided. Coming back up to speed on that which we do remember also takes time and effort. Unless we are lucky enough to have our work accepted on its first submission, we must disrupt our other work to revise our submission <!-- fixme, moving concepts to next block --> to target a different publication, with different reviewers, with different interests, paper formatting rules, and other expectations.

<a id="negative-feedback"></a>
#### It creates a culture of negative feedback
Conferences and journals that reject a majority of papers will necessarily provide more negative feedback to the community than positive feedback. Peer review committees may try to encourage reviewers to list some positives for every paper and to be constructive in presenting negative feedback, but the overriding feedback must still support rejection when justifying that outcome. 

#### It makes us complicit in others' negative feedback
When peer review produces toxic feedback for authors is also harmful to us as reviewers. When we review alongside those who abuse the subjectivity and anonymity of peer review, we are obligated to protect their anonymity while witnessing the resulting harms.

Without alternatives to exclusionary peer review, we cannot fulfill our scientific duty to review others' work without rejecting a significant portion of us, and becoming complicit in the system built on top of those rejections.

#### It creates tedious work that does not further science
Each re-submission must be updated not just to respond to any legitimately constructive feedback, but also to cater to the different interests, paper formatting rules, and other expectations of the next peer review committee.

<span id="audience"></span>
#### It makes us write for reviewers, not our intended audience
To craft papers to be accepted by reviewers, we write defensively, at a cost to our intended audience and our integrity. We may effusively cite work by likely reviewers, even if we the work is only tangentially related and we are skeptical of it. We add volumes of citations to signal to reviewers that we are experts in the field, even if we don't think many are worth reading. This need to signal expertise has caused research bibliographies to evolve like peacock's trains: vast assemblies of plumage, most of which serve no purpose but to attract those who co-evolved to prize it.

As we authors write to conform, not inform, papers have grown to meet reviewers' ever increasing expectations for citation counts, and with cited work receiving less explanation of why its relevant to help the non-expert reader. We also conform by maximizing the amount of information that can fit of a page limit (to maximize the "contribution" needed for acceptance), and using our full page limit, rather than publishing shorter (or longer) papers.

<a id="writing-less-scientifically"></a>
#### It makes us authors write less scientifically
Authors may elide mundane details of experimental designs that reviewers might find tedious, even if those details would be needed to replicate their experiments. Authors may highlight experiments or tests that yielded a statistically significant result and dedicate less space to those that reviewers will find less interesting. Authors may be tempted to deceive others, and even themselves, into believing that hypothesis tests they conducted on data they found interesting were planned before they had seen the data (or [HARKing](./Recommended-Readings.md#HARKing-Hypothesizing-After-the-Results-are-Known)).

Authors may be tempted to aggrandize their research to look more important. In some fields (including [mine](./Notes.md#speculation)), researchers are even pressured by reviewers to go beyond factual reporting of results to speculate about their research's impact and importance.

<a id="biasing-science"></a>
#### It biases the demographics of science

The predominance of negative feedback biases who becomes a scientist. The scientific community loses talented aspiring scientists who are uncomfortable promoting their work as important, or who are too "thin-skinned" or "insufficiently perseverant" to discard feedback that argues their work is unimportant. While the ability to overcome challenges is an asset in science and most professions, expecting persistence in the face of negative feedback causes at least two selection biases in who survives the process of becoming a scientist.

First, it makes those more comfortable promoting the importance of their work, or whose sheer self confidence allows them to dismiss negative feedback, most likely survive. Those who believe others will be interested the research they've conducted, and are most able to ignore reviewers' disinterest, may also be the most able to ignore experimental results that refute their preconceptions. Some have even argued that natural selection favors scientists whose “poor” methods “produce the greatest number of publishable results” which leads to “increasingly high false discovery rates” [[Smaldino and McElreath]](./Recommended-Readings.md/#the-natural-selection-of-bad-science).

Second, exclusionary peer review may also make it harder to fix science's inclusivity problems, as aspiring scientists from underrepresented groups must write for gatekeepers selected from a pool they are underrepresented in, and may face other systemic challenges that could make them vulnerable to feedback that reinforces the other factors that make them predisposed to feel unwelcome.

# Peer Review Should *Elucidate*, not *Exclude*.

We scientists say we practice peer review to protect the scientific integrity of research: employing objective experts to identify its flaws, evaluate its credibility, and ensure that it does not confuse or mislead.
<!-- Since we have convinced the press and public that peer review is a signal that research is credible, we *should* make paramount the goal of preventing research from misleading. -->

But in much of science, what we are actually doing when we peer review research is to rank it relative to other research competing for attention and, by extension, [to rank our fellow scientists relative to each other](to-rank-our-fellow-scientists-relative-to-each-other). Peer review committees are run by journals and conferences, each of which has its own brand, and which signal brand prestige by being ‘*selective*’ in which submissions they accept. Maintaining a prestigious brand requires excluding some submissions of acceptable scientific integrity.

***Exclusionary* peer review** remains the current practice even though restricting publication is now vestigial to science. There were once financial constraints on how much could be published: when research was printed on paper, traveled by mail, and took up space on shelves. As publishing costs approached zero and the information available to us grew exponentially, we acquired new tools to filter the deluge of information competing for our attention. We no longer need peer reviewers to be arbiters of fashion, curating which research is worthy of modeling on science's most exclusive runways and which to leave hanging backstage in science's sweaty dressing rooms. Nor is there evidence that are we reliable judges of even other experts' tastes. On the contrary, in well-designed experiments testing the replicability of exclusionary peer review, [half of papers accepted by one review were rejected by a parallel review](./Notes.md#replicability).
<!-- Perhaps for the slide version of this talk "Runways are an odd slightly-raised surface for scientists to choose to die on." or "When I ask fellow scientists whether they really want to be arbiters of fashion, I'm often surprised how many will choose a runway as the hill they're willing to die on." -->

***Elucidative* peer review** would *not* ask experts to decide whether work should be published, but only to share their insights for the work's eventual audience. Their job would be to ensure that when the work is published, those in its audience who are less expert than they are, or who read it less carefully than they do, are not mislead or otherwise unaware of the work's limitations. Whereas exclusionary peer review demands that scientists to pass final judgements, *elucidative* peer review only requires us to use the skills essential to writing our own papers: consuming others' research and explaining it to readers.

In this article, I will explain why elucidative peer review is benefits us authors of research, consumers (the audience), reviewers, and benefits the broader scientific community and its place in society.


<!-- 



 -->
## How we benefit, as authors, when publishing research

The [social contract](./Notes.md#social-contract) of elucidative peer review requires us, as authors, to share the elucidative peer reviews we receive with our audience when our work is published. If we want to publish a revision before the reviews are updated in response, or if reviewers are unwilling or unable to respond, we must also share the last version(s) reviewed by each reviewer, illuminating what we have changed since they last weighed in.

**As authors**, preparing work for elucidative peer review allows us to write for our intended audience, prioritizing scientific content over reviewers' subjective interests. We can expect feedback to be more constructive and timely. We need only wait for reviewers to read and respond to our work to get feedback, and we need only wait until we are satisfied that we have sufficiently addressed reviewers concerns to publish it.

#### We can reduce the time to publish peer-reviewed research
**Exclusionary peer review delays the spread of knowledge**. Because comparing competing submissions takes time, authors must often wait to submit their research until a common deadline, reviewers need time to read a cohort of submissions to compare them against each other, and committees need time to collectively discuss which papers to accept. These delays can add months to each submission cycle. Research that needs to be submitted three times to find a publication that considers it on brand may take over a year to be accepted and longer to publish. In many fields, the value of research can decline significantly while it awaits a single round of exclusionary peer review (with extreme examples being research on the detection and prevention of emerging diseases or of research identifying election misinformation campaigns).

#### We can write for our true audience
**Writing for exclusionary review prevents us from writing for our true audience**. To craft papers to be accepted by reviewers, authors must make sacrifices in serving their intended audience. For example, as authors we often add volumes of citations of no value to anyone but our reviewers. We do so to signal to reviewers that we are experts in the field and to reduce the chance of being faulted for failing to cite a reviewer's favorite work. Since reviewers expect papers to have at least as many citations as previously-accepted work, we add even more unnecessary citations when writing on relatively new topics, for which few prior works are truly relevant. As we authors write to conform, not inform, papers have grown to meet reviewers' ever increasing expectations for citation counts, and with cited work receiving less explanation of why its relevant to help the non-expert reader. We also conform by maximizing the amount of information that can fit of a page limit (to maximize the "contribution" needed for acceptance), and using our full page limit, rather than publishing shorter (or longer) papers.

#### We can write more scientifically
**Making research appeal to reviewers causes authors to write less scientifically**. Authors may elide mundane details of experimental designs that reviewers might find tedious, even if those details would be needed to replicate their experiments. Authors may highlight experiments or tests that yielded a statistically significant result and dedicate less space to those that reviewers will find less interesting. Authors may be tempted to deceive others, and even themselves, into believing that hypothesis tests they conducted on data they found interesting were planned before they had seen the data (or [HARKing](./Recommended-Readings.md#HARKing-Hypothesizing-After-the-Results-are-Known)).

Authors may be tempted to aggrandize their research to look more important. In some fields (including [mine](./Notes.md#speculation)), researchers are even pressured by reviewers to go beyond factual reporting of results to speculate about their research's impact and importance.


#### We receive feedback while our memories are still fresh
**Delays disrupt authors' work and degrade our memories**. Time decays our ability to recall how we conducted our experiments, our observations during the experiments, and the tooling we used to process data and document our results. By the time have access to reviewers' feedback identifying what we failed to document, we may have already forgotten details that reviewers noticed we had elided. Coming back up to speed on that which we do remember also takes time and effort. Unless we are lucky enough to have our work accepted on its first submission, we must disrupt our other work to revise our submission to target a different publication, with different reviewers, with different interests, paper formatting rules, and other expectations.

#### We can get feedback earlier in the research process

Using elucidative peer review, we could even submit our experimental methodology for feedback, using reviewers' insights to improve those experimental designs *prior* to running experiments and reporting results. We could then seek further feedback after completing the research. Currently, peer review only reveals experimental design flaws after we have spent all the resources needed to run an experiment, and often after key co-authors have graduated or started other jobs.

#### We get less negative (toxic) feedback

Conferences and journals that reject a majority of papers will necessarily provide more negative feedback to the community than positive feedback. Peer review committees may try to encourage reviewers to list some positives for every paper and to be constructive in presenting negative feedback, but the overriding feedback must still support rejection when justifying that outcome. 


As authors, we may disagree with those who review our work, as we do today. We may choose to rebut their concerns within the work or through separate commentary. As reviewers, we can assist authors by noting if we find others' reviews inaccurate or prejudicial. We may also weigh in even when not formally reviewing, either through our reviewing systems or through other means of public discourse. Elucidating disagreements amongst scientists gives our audience a more accurate and nuanced view of how science works than summarizing it into a single ‘*accept*’ or ‘*reject*’ decision.


## How we benefit as consumers of others' research

**As consumers** of research, elucidative peer review provides objective insight into the credibility of that research, written to be accessible to non-experts. When authors opt for elucidative peer review, we in their audience get access to their research sooner—we we do not need to wait for authors to submit and re-submit their work until finding a peer review committee that consider it worthy of publication.

We should also demand more control over the decisions that guide our access to research that interests us, rather than what others think we should find worth reading. For example, we could eschew conferences where an elite group of peer reviewers decide what which presentations we want to see, and instead opt for those that ask us which prospective presentations we would want to see and allocate speaker slots and lecture hall sizes to give the audience what we're actually interested in.

#### Faster access to information

## How we benefit as reviewers of others' research

When reviewing, we can not only elucidate concerns to share with those who might learn about the work (as journalists are limited to), but we can attempt to persuade authors to revise their work to address those concerns. It is better for authors to eliminate our causes for concern, or disclose those concerns on their own, than for the audience to only learn about the concerns from our reviews. (When authors address our concerns, we can remove those concerns from our reviews or note if we are satisfied with authors' changes.)

participating in elucidative peer review allows us to perform a service to authors, and to serve science more broadly, without being complicit in ranking and exclusion. Elucidative reviewing gives our reviews a higher purpose and broader audience than exclusionary reviewing. It also lightens our reviewing workloads, as authors need not resubmit their work repeatedly in search of reviewers who consider their work interesting enough to publish—each work needs only one set of reviewers.

#### We can free ourselves from outcome bias

However, when reviewers have to make a decision to accept or reject research, and start favoring one of those two options during the review process, they may consciously or subconsciously start biasing their collection and presentation of evidence to support the position they expect their review to take. Only by eliminating the decision entirely can we remove this bias.

Also, the choice to ‘*reject*’ research implies that there is also a decision to ‘*accept*’ it. Whenever we ‘*accept*’ research we risk that this act will be perceived as scientific consensus on correctness, when in fact it would only mean that none of a small number of experts found sufficient reason to reject it. Science takes a long time to build consensus around our confidence in results. When the public prematurely concludes finality and correctness, then sees conflicting results later also endorsed with an ‘*accept*’, they may lose faith in science.

#### We can free ourselves from reviewing work others have already provided sufficient feedback on
Having countless exclusionary peer review committees of different strata also burdens us with unnecessary work as reviewers. We must re-review papers that had already met scientific-integrity requirements when previously rejected. Our efforts to provide constructive feedback are discarded by authors who assume that what their work really needs is a new set of reviewers with different subjective expectations.

#### We don't have to participate in the culture of rejection

#### Toxicity
When peer review produces toxic feedback for authors is also harmful to us as reviewers. When we review alongside those who abuse the subjectivity and anonymity of peer review, we are obligated to protect their anonymity while witnessing the resulting harms.

Without alternatives to exclusionary peer review, we cannot fulfill our scientific duty to review others' work without rejecting a significant portion of us, and becoming complicit in the system built on top of those rejections.


## Benefits for science

There are many ways using peer review to rank research, and determine which research is worth publishing, harms scientific writing and causes science to mislead ourselves and others. (See the [recommended readings](./Recommended-Readings.md) for additional background on these flawed scientific practices.)

#### The body of published results will be less biased
**Excluding research biases the body of published results**. Submissions that confirm the hopes and beliefs of reviewers are more likely to be accepted than those that defy reviewers' expectations or dash their hopes. Among the many consequences of *publication bias* the potential for false discovery, especially when peer review committees deem null results unworthy of publication. If twenty research teams test an attractive but ineffective intervention, we can expect 19 teams to find no significant difference and fail to publish. We can expect one of twenty to find specious support the attractive-but-false hypothesis that the intervention is effective (at least at p<0.05)—and get published.

#### Peer review will mean what we say it means
**Stratification built on exclusionary peer review undermines scientific standards**. Every journal and conference has different standards of acceptance. Many journals and conferences publish work they know to be flawed to meet financial or attendance goals. The lowest strata publications may provide the pretense of peer review while accepting any paper for which authors pay publication fees. Even the most prestigious conferences in my field are known to override some reviewer's integrity concerns if others believe the work will draw attention that might otherwise go to competing conferences. Yet, many outsiders are unfamiliar with these different standards, or are unaware that scientific standards vary so broadly depending on the publication.

<!-- --- -->
#### We will broaden and improve participation in science
#### Exclusionary peer review biases the demographics of science

The predominance of negative feedback biases who becomes a scientist. The scientific community loses talented aspiring scientists who are uncomfortable promoting their work as important, or who are too "thin-skinned" or "insufficiently perseverant" to discard feedback that argues their work is unimportant. While the ability to overcome challenges is an asset in science and most professions, expecting persistence in the face of negative feedback causes at least two selection biases in who survives the process of becoming a scientist.

First, it makes those more comfortable promoting the importance of their work, or whose sheer self confidence allows them to dismiss negative feedback, most likely survive. Those who believe others will be interested the research they've conducted, and are most able to ignore reviewers' disinterest, may also be the most able to ignore experimental results that refute their preconceptions. Some have even argued that natural selection favors scientists whose “poor” methods “produce the greatest number of publishable results” which leads to “increasingly high false discovery rates” [[Smaldino and McElreath]](./Recommended-Readings.md/#the-natural-selection-of-bad-science).

Second, exclusionary peer review may also make it harder to fix science's inclusivity problems, as aspiring scientists from underrepresented groups must write for gatekeepers selected from a pool they are underrepresented in, and may face other systemic challenges that could make them vulnerable to feedback that reinforces the other factors that make them predisposed to feel unwelcome.




---

Stuart Schechter wrote this article with the inspiration and help of many (some noted [here](./Acknowledgements.md)). Those who might dismiss Stuart's arguments by concluding that he is sort of mad scientist would be wise to consider an alternate hypothesis, that they may have only seen him mildly aggrieved. You can follow him at [@MildlyAggrievedScientist@mastodon.social](https://mastodon.social/@MildlyAggrievedScientist).

---

[Acknowledgements](./Acknowledgements.md) | [FAQ](./FAQ.md) | [Notes](./Notes.md) | [Recommended readings](Recommended-Readings.md)
<!-- em — , en –   …  -->

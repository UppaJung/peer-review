# Peer Review Should *Elucidate*, not *Exclude*.

We scientists say we practice peer review to protect the scientific integrity of research: employing objective experts to identify its flaws, evaluate its credibility, and ensure that it does not confuse or mislead.
<!-- Since we have convinced the press and public that peer review is a signal that research is credible, we *should* make paramount the goal of preventing research from misleading. -->

But in much of science, what we are actually doing when we peer review research is to rank it relative to other research competing for attention and, by extension, [to rank our fellow scientists relative to each other](to-rank-our-fellow-scientists-relative-to-each-other). Peer review committees are run by journals and conferences, each of which has its own brand, and which signal brand prestige by being ‘*selective*’ in which submissions they accept. Maintaining a prestigious brand requires excluding some submissions of acceptable scientific integrity.

Perversely, we practice *exclusionary* peer review even though its function of limiting what can be published is now vestigial to science. There were once financial forces that made information exchange expensive and constrained how much could be published: when research was printed on paper, traveled by mail, and took up space in libraries. While we may have once needed reviewers to determine what was worth publishing, we do not in an era where publication is effectively free. As the information available to us has grown exponentially, and we have faced a deluge of information competing for our attention, we acquired new tools to filter it to focus on what interests us, such as search engines and social media sharing. We no longer need peer reviewers to be arbiters of fashion, curating which research is worthy of modeling on science's most exclusive runways and which to leave hanging backstage in science's sweaty dressing rooms.
<!-- Perhaps for the slide version of this talk "Runways are an odd slightly-raised surface for scientists to choose to die on." or "When I ask fellow scientists whether they really want to be arbiters of fashion, I'm often surprised how many will choose a runway as the hill they're willing to die on." -->

And we continue to practice *exclusionary* peer review without evidence that we scientists are even reliable judges of what others consider worth publishing. The scant evidence we do have include two well-designed experiments testing the replicability of exclusionary peer review, in which [half of papers accepted by one review were rejected by a parallel review](./Notes.md#replicability).

The alternative to *exclusionary* peer review is for works to be reviewed by scientific experts who do *not* to decide whether it should be published, but to instead elucidate their findings for the work's audience. They write reviews to ensure that when the work is published, its less-expert audience is not mislead or otherwise unaware of its limitations. Whereas exclusionary peer review demands that scientists act as judges and arbiters fo fashion, *elucidative* peer review only requires scientists use the skills essential to writing our own papers: consuming others' research and explaining it to readers.

In this article, I will detail many of the ways that using *exclusionary* peer review to vet scientific research makes writing less scientific, is antithetical to scientific integrity, and is harmful to those who practice science. In other words, those who say we conduct exclusionary peer review to prevent scientists from misleading themselves and the public are misrepresenting peer review in a way that misleads themselves and the public.

Looking at peer review as a system for establishing consensus around truth, I'll examine other such systems outside science that attempt to accomplish similar goals to bring outside perspective. I'll then explain what makes *elucidative* peer review different from exclusionary peer review and its advantages for both scientists and our audience.


## Exclusionary peer review harms science and scientists

There are many ways using peer review to rank research, and determine which research is worth publishing, harms scientific writing and causes science to mislead ourselves and others. (See the [recommended readings](./Recommended-Readings.md) for additional background on these flawed scientific practices.)

**Excluding research biases the body of published results**. Submissions that confirm the hopes and beliefs of reviewers are more likely to be accepted than those that defy reviewers' expectations or dash their hopes. Among the many consequences of *publication bias* the potential for false discovery, especially when peer review committees deem null results unworthy of publication. If twenty research teams test an attractive but ineffective intervention, we can expect 19 teams to find no significant difference and fail to publish. We can expect one of twenty to find specious support the attractive-but-false hypothesis that the intervention is effective (at least at p<0.05)—and get published.

**Making research appeal to reviewers causes authors to write less scientifically**. Authors may elide mundane details of experimental designs that reviewers might find tedious, even if those details would be needed to replicate their experiments. Authors may highlight experiments or tests that yielded a statistically significant result and dedicate less space to those that reviewers will find less interesting. Authors may be tempted to deceive others, and even themselves, into believing that hypothesis tests they conducted on data they found interesting were planned before they had seen the data (or [HARKing](./Recommended-Readings.md#HARKing-Hypothesizing-After-the-Results-are-Known)).

Authors may be tempted to aggrandize their research to look more important. In some fields (including [mine](./Notes.md#speculation)), researchers are even pressured by reviewers to go beyond factual reporting of results to speculate about their research's impact and importance.

**Making reviewers gatekeepers changes the audience research is written for**. To craft papers to be accepted by reviewers, authors must make sacrifices in serving their intended audience. For example, as authors we often add volumes of citations of no value to anyone but our reviewers. We do so to signal to reviewers that we are experts in the field and to reduce the chance of being faulted for failing to cite a reviewer's favorite work. Since reviewers expect papers to have at least as many citations as previously-accepted work, we add even more unnecessary citations when writing on relatively new topics, for which few prior works are truly relevant. As we authors write to conform, not inform, papers have grown to meet reviewers' ever increasing expectations for citation counts, and with cited work receiving less explanation of why its relevant to help the non-expert reader. We also conform by maximizing the amount of information that can fit of a page limit (to maximize the "contribution" needed for acceptance), and using our full page limit, rather than publishing shorter (or longer) papers.

**Exclusionary peer review delays the spread of knowledge**. Because comparing competing submissions takes time, authors must often wait to submit their research until a common deadline, reviewers need time to read a cohort of submissions to compare them against each other, and committees need time to collectively discuss which papers to accept. These delays can add months to each submission cycle. Research that needs to be submitted three times to find a publication that considers it on brand may take over a year to be accepted and longer to publish. In many fields, the value of research can decline significantly while it awaits a single round of exclusionary peer review (with extreme examples being research on the detection and prevention of emerging diseases or of research identifying election misinformation campaigns).

**Delays disrupt authors' work and degrade our memories**. Time decays our ability to recall how we conducted our experiments, our observations during the experiments, and the tooling we used to process data and document our results. By the time have access to reviewers' feedback identifying what we failed to document, we may have already forgotten details that reviewers noticed we had elided. Coming back up to speed on that which we do remember also takes time and effort. Unless we are lucky enough to have our work accepted on its first submission, we must disrupt our other work to revise our submission to target a different publication, with different reviewers, with different interests, paper formatting rules, and other expectations.

**Stratification built on exclusionary peer review undermines scientific standards**. Every journal and conference has different standards of acceptance. Many journals and conferences publish work they know to be flawed to meet financial or attendance goals. The lowest strata publications may provide the pretense of peer review while accepting any paper for which authors pay publication fees. Even the most prestigious conferences in my field are known to override some reviewer's integrity concerns if others believe the work will draw attention that might otherwise go to competing conferences. Yet, many outsiders are unfamiliar with these different standards, or are unaware that scientific standards vary so broadly depending on the publication.

<!-- --- -->

**Exclusionary peer reviewing causes broader harms to science**.

Conferences and journals that reject a majority of papers will necessarily provide more negative feedback to the community than positive feedback. Peer review committees may try to encourage reviewers to list some positives for every paper and to be constructive in presenting negative feedback, but the overriding feedback must still support rejection when justifying that outcome. 

The predominance of negative feedback biases who becomes a scientist. The scientific community loses talented aspiring scientists who are uncomfortable promoting their work as important, or who are too "thin-skinned" or "insufficiently perseverant" to discard feedback that argues their work is unimportant. While the ability to overcome challenges is an asset in science and most professions, expecting persistence in the face of negative feedback causes at least two selection biases in who survives the process of becoming a scientist.

First, it makes those more comfortable promoting the importance of their work, or whose sheer self confidence allows them to dismiss negative feedback, most likely survive. Those who believe others will be interested the research they've conducted, and are most able to ignore reviewers' disinterest, may also be the most able to ignore experimental results that refute their preconceptions. Some have even argued that natural selection favors scientists whose “poor” methods “produce the greatest number of publishable results” which leads to “increasingly high false discovery rates” [[Smaldino and McElreath]](./Recommended-Readings.md/#the-natural-selection-of-bad-science).

Second, exclusionary peer review may also make it harder to fix science's inclusivity problems, as aspiring scientists from underrepresented groups must write for gatekeepers selected from a pool they are underrepresented in, and may face other systemic challenges that could make them vulnerable to feedback that reinforces the other factors that make them predisposed to feel unwelcome.

Having countless exclusionary peer review committees of different strata also burdens us with unnecessary work as reviewers. We must re-review papers that had already met scientific-integrity requirements when previously rejected. Our efforts to provide constructive feedback are discarded by authors who assume that what their work really needs is a new set of reviewers with different subjective expectations.

When peer review produces toxic feedback for authors is also harmful to us as reviewers. When we review alongside those who abuse the subjectivity and anonymity of peer review, we are obligated to protect their anonymity while witnessing the resulting harms.

Without alternatives to exclusionary peer review, we cannot fulfill our scientific duty to review others' work without rejecting a significant portion of us, and becoming complicit in the system built on top of those rejections.



## We can learn from other systems for establishing shared beliefs

Peer review is part of a larger system of rituals that scientists use to build consensus around beliefs. In reevaluating peer review, it is worth stepping back to evaluate how other systems establish consensus beliefs.

Justice systems investigate and seek to test hypotheses where lives hang in the balance: did someone ("a suspect") commit a criminal offense for which they should be punished. As anyone familiar with [procedural television dramas](./Notes.md#regarding-procedural-television-dramas) knows, the criminal justice system separates the roles of investigating crimes from those who prosecute the offenders, advocating for the conclusion of guilt. Since those who choose to investigate a suspect, and put in effort to conduct the investigation, may become invested in believing the hypothesis of guilt, someone more objective evaluates the collected evidence to decide whether it is strong enough to support advocating for the hypothesis of guilt (prosecution). Then, the prosecutor must advocate to a panel of members of the public, a jury, who make the final judgement.

From the perspective of those in criminal justice – with all its unjust flaws that corrupt and bias it – how much more corrupt science must seem; first, for allowing researchers to both investigate a hypothesis they are invested in and advocate for a conclusion; and second, for placing final judgement in the hands of anonymous investigators, some of whom may have advocated for (or still be advocating for) similar or competing conclusions. We should eschew practices that encourages scientists to draw judgments beyond that which is immediately inferrable from the evidence presented. We should also avoid practices that discard peers' insights into research and replace them with a boolean indicator of credibility (accept/reject) that we present as if it represented some broader scientific consensus.

We can also learn from journalists, who are also investigators who face decisions about what facts to treat as shared truths and who must reckon with their larger role of establishing shared beliefs. Those journalists who strive for impartiality (a valuable, if endangered, species) try to let the observations they report speak for themselves.

For a model of how we might prevent research from misleading without gatekeeping what gets published, we might look to how the most diligent journalists report on new scientific research: they reach out to multiple objective scientific experts, ask those experts to speak to the credibility of research and the conclusions that might be drawn from it, and quote those experts so that readers know exactly what they said. When experts use language that may be unfamiliar to a broader audience, the best journalists help make it understandable to that audience.

The model of investigative journalism is *elucidative*: it informs the audience about observed disagreements rather than declaring the winner.

Our practice of submitting research for exclusionary peer review, and gatekeeping for exclusionary peer review, demands that we scientists be investigators, advocates, and jurors. The latter two roles should give us pause. Science is more objective and credible when our role as investigators comes first.

The better we are able to investigate and elucidate our findings so that others can understand them, the better they can come to the most accurate conclusions on their own and build a shared consensus.

When conducting research as scientific investigators, we should be wary of any obligation to advocate for conclusions, especially those that promote the significance or importance of our results. When acting as peer reviewers to investigate others' work for errors, misleading statements, or other shortcomings, we should also be wary of any obligation to go beyond elucidating our findings, such as drawing conclusions about whether the work is worthwhile.



## Peer review need only investigate and elucidate

In *elucidative* peer review, objective experts investigate a research work and provide insights to ensure non-experts (or less meticulous readers) are not mislead by the work or otherwise unaware of its important limitations. Unlike *exclusionary* peer review, reviewers do not decide whether to accept or reject the work for publication ([FAQ: Why not conduct exclusionary peer review evaluating only scientific integrity?](./FAQ.md#Why-not-conduct-exclusionary-peer-review-evaluating-only-scientific-integrity)). Instead, reviewers direct their feedback to audience of the research, to be shared with that audience alongside the research when it is published. Reviewers may also provide suggestions to the authors to help the authors prevent their audience from being confused or mislead.

When reviewing, we can not only elucidate concerns to share with those who might learn about the work (as journalists are limited to), but we can attempt to persuade authors to revise their work to address those concerns. It is better for authors to eliminate our causes for concern, or disclose those concerns on their own, than for the audience to only learn about the concerns from our reviews. (When authors address our concerns, we can remove those concerns from our reviews or note if we are satisfied with authors' changes.)

As authors, we may disagree with those who review our work, as we do today. We may choose to rebut their concerns within the work or through separate commentary. As reviewers, we can assist authors by noting if we find others' reviews inaccurate or prejudicial. We may also weigh in even when not formally reviewing, either through our reviewing systems or through other means of public discourse. Elucidating disagreements amongst scientists gives our audience a more accurate and nuanced view of how science works than summarizing it into a single ‘*accept*’ or ‘*reject*’ decision.

When we are ready to publish work we have authored as scientifically peer reviewed in the elucidative model, we are required to share the reviews with audience. If we want to publish a revision before the reviews are updated in response, or if reviewers are unwilling or unable to respond, we must also share the last version(s) reviewed by each reviewer, illuminating what we have changed since they last weighed in.


## Elucidative peer review is better for scientists and those we serve

Adopting elucidative peer review would benefit us whether we are authoring, reviewing, or consuming research.

**As reviewers**, participating in elucidative peer review allows us to perform a service to authors, and to serve science more broadly, without being complicit in ranking and exclusion. Elucidative reviewing gives our reviews a higher purpose and broader audience than exclusionary reviewing. It also lightens our reviewing workloads, as authors need not resubmit their work repeatedly in search of reviewers who consider their work interesting enough to publish—each work needs only one set of reviewers.

**As authors**, preparing work for elucidative peer review allows us to write for our intended audience, prioritizing scientific content over reviewers' subjective interests. We can expect feedback to be more constructive and timely. We need only wait for reviewers to read and respond to our work to get feedback, and we need only wait until we are satisfied that we have sufficiently addressed reviewers concerns to publish it.

Using elucidative peer review, we could even submit our experimental methodology for feedback, using reviewers' insights to improve those experimental designs *prior* to running experiments and reporting results. We could then seek further feedback after completing the research. Currently, peer review only reveals experimental design flaws after we have spent all the resources needed to run an experiment, and often after key co-authors have graduated or started other jobs.

**As consumers** of research, elucidative peer review provides objective insight into the credibility of that research, written to be accessible to non-experts. When authors opt for elucidative peer review, we in their audience get access to their research sooner—we we do not need to wait for authors to submit and re-submit their work until finding a peer review committee that consider it worthy of publication.

We should also demand more control over the decisions that guide our access to research that interests us, rather than what others think we should find worth reading. For example, we could eschew conferences where an elite group of peer reviewers decide what which presentations we want to see, and instead opt for those that ask us which prospective presentations we would want to see and allocate speaker slots and lecture hall sizes to give the audience what we're actually interested in.

**Those who stand to lose** by the adoption of elucidative peer review are not scientists or the public we serve, but the journals and conferences which use the veneer of scientific integrity to perpetuate exclusionary peer review in service of their brands. They are the churches and temples whose survival has depended on our perverse willingness to perpetuate an anachronistic bloodletting ritual—to collectively torture ourselves with our own negative feedback.

<!-- 
Add institutions that rely on scientists to rank each other, like hiring committees.
Not that NSF avoid accept/reject and de-emphasizes it's ordinal scores over elucidation. (5 scores, but with half scores really 9)

From NSF instructions: "The rating is NOT the most critical aspect of a review -- of far more value are comments on the advantages and disadvantages of the proposal"
 -->

They stand to lose their near monopoly on the distribution of scientific credibility that makes us seek their approval, and their near monopoly on reviewing service.

We may feel some regret hastening the demise of the journals whose acceptances have advanced our rankings in science's stratification system, and whose peer review committees provided us with camaraderie. We should recognize that it is common for the victims in abusive relationships to become dependent on the approval of our abusers, and to even want to protect them.

But exclusionary peer review and the institutions that perpetuate it do not serve science. To preserve the credibility of the scientific endeavor, we must reject the notion that they do.

---

Stuart Schechter wrote this article with the inspiration and help of many (some noted [here](./Acknowledgements.md)). Those who might dismiss Stuart's arguments by concluding that he is sort of mad scientist would be wise to consider an alternate hypothesis, that they may have only seen him mildly aggrieved. You can follow him at [@MildlyAggrievedScientist@mastodon.social](https://mastodon.social/@MildlyAggrievedScientist).

---

[Acknowledgements](./Acknowledgements.md) | [FAQ](./FAQ.md) | [Notes](./Notes.md) | [Recommended readings](Recommended-Readings.md)
<!-- em — , en –   …  -->
